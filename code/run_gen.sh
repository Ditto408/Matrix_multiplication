#!/bin/bash

# ================= é…ç½®åŒºåŸŸ =================
# 1. ä½¿ç”¨çº¯ Python ç”Ÿæˆå™¨
BASE_DIR="/home/spark/work/Matrix_multiplication"
GEN_CODE="$BASE_DIR/code/datagen.py"

# 2. è·¯å¾„é…ç½®
HDFS_ROOT="hdfs://spark-master:9000/input"
LOCAL_DATA_ROOT="$BASE_DIR/data"

# ===========================================

# åˆ›å»ºæœ¬åœ°æ•°æ®ç›®å½•
mkdir -p $LOCAL_DATA_ROOT

echo "========================================="
echo "ğŸš€ å¼€å§‹ç”Ÿæˆå®éªŒæ•°æ® (å…¨åœºæ™¯è¦†ç›–ç‰ˆ)"
echo "ç­–ç•¥: æœ¬åœ°ç”Ÿæˆ -> ä¸Šä¼  HDFS"
echo "========================================="

run_gen() {
    local ROWS=$1
    local COLS=$2
    local SPARSITY=$3
    local NAME=$4 

    # å®šä¹‰æ–‡ä»¶å
    local FILE_A="${LOCAL_DATA_ROOT}/A_${NAME}.txt"
    local FILE_B="${LOCAL_DATA_ROOT}/B_${NAME}.txt"
    
    # å®šä¹‰ HDFS ç›®æ ‡æ–‡ä»¶å¤¹
    local HDFS_A="${HDFS_ROOT}/A_${NAME}"
    local HDFS_B="${HDFS_ROOT}/B_${NAME}"

    echo "-----------------------------------------"
    echo "æ­£åœ¨å¤„ç†ç»„: [${NAME}]"
    echo "è§„æ¨¡: ${ROWS}x${COLS} | ç¨€ç–åº¦: ${SPARSITY}"
    echo "-----------------------------------------"

    # 1. æœ¬åœ°ç”Ÿæˆ (ä¸²è¡Œæ‰§è¡Œï¼Œç»å¯¹ç¨³)
    echo " [1/4] Generating Matrix A locally..."
    if [ ! -f "$FILE_A" ]; then
        python3 $GEN_CODE $ROWS $COLS $SPARSITY $FILE_A
    else
        echo "    -> æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆã€‚"
    fi

    echo " [2/4] Generating Matrix B locally..."
    if [ ! -f "$FILE_B" ]; then
        python3 $GEN_CODE $ROWS $COLS $SPARSITY $FILE_B
    else
        echo "    -> æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆã€‚"
    fi

    # 2. æ¸…ç† HDFS æ—§æ•°æ®
    echo " [3/4] Cleaning HDFS..."
    hadoop fs -rm -r $HDFS_A > /dev/null 2>&1
    hadoop fs -rm -r $HDFS_B > /dev/null 2>&1
    
    # 3. ä¸Šä¼ åˆ° HDFS
    echo " [4/4] Uploading to HDFS..."
    
    # ä¸Šä¼ ä¸ºæ–‡ä»¶å¤¹ç»“æ„ (part-00000) ä»¥é€‚é… Spark è¯»å–é€»è¾‘
    hadoop fs -mkdir -p $HDFS_A
    hadoop fs -put $FILE_A $HDFS_A/part-00000
    
    hadoop fs -mkdir -p $HDFS_B
    hadoop fs -put $FILE_B $HDFS_B/part-00000

    echo "âœ… ç»„ [${NAME}] å…¨éƒ¨å®Œæˆï¼"
}

# ===========================================
# åœºæ™¯ Aï¼šç¨ å¯†çŸ©é˜µ (Dense Matrix)
# ===========================================
# ç›®çš„ï¼šæµ‹è¯• SystemML å’Œ Spark åœ¨æ— ç¨€ç–ä¼˜åŒ–ä¸‹çš„â€œç¡¬è®¡ç®—â€èƒ½åŠ›
echo ">>> [Group A] æ‰§è¡Œç¨ å¯†çŸ©é˜µç”Ÿæˆ..."
run_gen 500 500 1.0 "Dense_500"
run_gen 1000 1000 1.0 "Dense_1000"
run_gen 2000 2000 1.0 "Dense_2000"

# ===========================================
# åœºæ™¯ Bï¼šè§„æ¨¡å¢é•¿ (Scale-up) - å›ºå®šç¨€ç–åº¦ 0.01
# ===========================================
# ç›®çš„ï¼šæµ‹è¯•æ•°æ®é‡å¢å¤§æ—¶çš„ç³»ç»Ÿæ‰©å±•æ€§
echo ">>> [Group B] æ‰§è¡Œè§„æ¨¡å¢é•¿ç”Ÿæˆ (sp=0.01)..."
run_gen 5000 5000 0.01 "Scale_0.01_5000"
run_gen 10000 10000 0.01 "Scale_0.01_10000"
run_gen 20000 20000 0.01 "Scale_0.01_20000"

# ğŸš€ã€æ–°å¢ã€‘å‹åŠ›æµ‹è¯• (5w x 5w)
# ä¼°ç®—ï¼š50000*50000*0.01 = 2500ä¸‡éé›¶å…ƒç´ ã€‚æ–‡æœ¬æ–‡ä»¶çº¦ 500MB~600MBã€‚
# è¿™æ˜¯é€¼å‡º SystemML Shuffle çš„å…³é”®ã€‚
echo ">>> [Stress Test] ç”Ÿæˆ 5w è§„æ¨¡æ•°æ® (å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)..."
run_gen 50000 50000 0.01 "Scale_0.01_50000"

# ===========================================
# åœºæ™¯ Cï¼šç¨€ç–åº¦æ•æ„Ÿæ€§ (Sparsity) - å›ºå®šè§„æ¨¡ 5000
# ===========================================
# ç›®çš„ï¼šåœ¨ 5000 è§„æ¨¡ä¸‹ï¼Œè§‚å¯Ÿä¸åŒç¨€ç–åº¦å¯¹å¹¿æ’­/è®¡ç®—çš„å½±å“
echo ">>> [Group C] æ‰§è¡Œç¨€ç–åº¦å˜åŒ–ç”Ÿæˆ (Scale=5000)..."
run_gen 5000 5000 0.001 "Sparsity_0.001_5000"
run_gen 5000 5000 0.05  "Sparsity_0.05_5000"
run_gen 5000 5000 0.1   "Sparsity_0.1_5000"

echo "========================================="
echo "ğŸ‰ æ‰€æœ‰æ•°æ®ç”Ÿæˆä»»åŠ¡ç»“æŸï¼"
echo "ğŸ‰ HDFS æ•°æ®å·²å°±ç»ªï¼Œè¯·æ›´æ–° run_experiments.sh å¯¹åº”è·¯å¾„ã€‚"
echo "========================================="